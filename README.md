# ğŸ§  Antonio AI - Self-Learning Edge Intelligence

**Antonio AI** is a production-ready, self-learning AI framework optimized for edge devices like Raspberry Pi. It features **EvoMemoryâ„¢** (persistent learning), **dual-model architecture** (SOCIAL + LOGIC), **RAG-Lite** retrieval, and **Power Sampling** research capabilities.

**Version**: 1.0.0  
**Author**: Antonio Consales  
**License**: Gemma License + MIT (code)

---

## ğŸ¯ Key Features

- ğŸ§¬ **EvoMemoryâ„¢** - Persistent memory with auto-learning
- ğŸ­ **Dual-Model System** - Smart switching between SOCIAL (conversation) and LOGIC (reasoning)
- ğŸ” **RAG-Lite** - BM25 retrieval without vector databases
- ğŸ”¬ **Power Sampling** - MCMC-based reasoning (research)
- âš¡ **Edge-Optimized** - Runs on Raspberry Pi 4 @ ~3.6 token/s
- ğŸŒ **Bilingual** - Italian & English support
- ğŸ¤ **Offline Voice Recognition** - OpenAI Whisper for speech-to-text (90+ languages)
- ğŸ”Š **Text-to-Speech** - Natural voice responses with ResponsiveVoice
- ğŸŒ **Web UI** - Modern interface with voice & text chat
- ğŸ³ **Docker Ready** - One-command deployment
- ğŸ”’ **100% Offline** - No external APIs required

---

## ğŸ“¦ Quick Start with Docker

```bash
# Clone repository
git clone https://github.com/antconsales/antonio-ai.git
cd antonio-ai

# Start with Docker Compose
docker-compose up -d

# Access API
curl http://localhost:8000/
```

**That's it!** Antonio is now running at `http://localhost:8000`

---

## ğŸš€ Manual Installation

### Prerequisites

- Python 3.9+
- [Ollama](https://ollama.com/) installed
- 4GB+ RAM

### Install

```bash
# Clone repository
git clone https://github.com/antconsales/antonio-ai.git
cd antonio-ai

# Install dependencies
pip install -r requirements.txt

# Pull models
ollama pull antconsales/antonio-gemma3-evo-q4              # SOCIAL (720MB)
ollama pull antconsales/antonio-gemma3-evo-q4-logic        # LOGIC (806MB)

# Start server
python start_server.py

# Access Web UI
# Open browser at http://localhost:8000/ui
```

---

## ğŸ“š Models

| Model | Type | Size | HuggingFace | Ollama | Use Case |
|-------|------|------|-------------|--------|----------|
| **SOCIAL** | Conversation | 720 MB | [chill123/antonio-gemma3-evo-q4](https://huggingface.co/chill123/antonio-gemma3-evo-q4) | `ollama pull chill123/antonio-gemma3-evo-q4` | Chat, storytelling |
| **LOGIC** | Reasoning | 806 MB | [chill123/antonio-gemma3-evo-q4-logic](https://huggingface.co/chill123/antonio-gemma3-evo-q4-logic) | [antconsales/antonio-gemma3-evo-q4-logic](https://ollama.com/antconsales/antonio-gemma3-evo-q4-logic) | Math, coding, logic |

---

## ğŸ¯ API Usage

### Web UI (Voice + Text Chat)

Open your browser at:
```
http://localhost:8000/ui
```

Features:
- Toggle voice/text input with microphone button
- Automatic language detection (90+ languages)
- Natural voice responses
- Dark/light theme
- Real-time transcription

### Basic Chat (API)

```bash
curl -X POST http://localhost:8000/chat \
  -H "Content-Type: application/json" \
  -d '{"message":"Ciao, come stai?"}'
```

### Voice Transcription (API)

```bash
curl -X POST http://localhost:8000/transcribe \
  -F "file=@audio.webm"
```

### With Power Sampling (Research)

```bash
curl -X POST http://localhost:8000/chat \
  -H "Content-Type: application/json" \
  -d '{"message":"Calculate Pythagorean theorem for sides 3 and 4","use_power_sampling":true}'
```

---

## ğŸ¤ Voice Recognition Setup

Antonio AI includes **100% offline voice recognition** powered by OpenAI Whisper.

### Prerequisites

```bash
# Install Whisper and audio dependencies
pip install openai-whisper

# Windows: FFmpeg is included in the project (ffmpeg-8.0-essentials_build/)
# Linux/Mac: Install FFmpeg
sudo apt install ffmpeg  # Ubuntu/Debian
brew install ffmpeg      # macOS
```

### Supported Languages

Whisper automatically detects and transcribes **90+ languages**, including:
- Italian (it)
- English (en)
- Spanish (es)
- French (fr)
- German (de)
- Portuguese (pt)
- And many more...

### How It Works

1. Click the microphone button in the Web UI
2. Speak in any supported language
3. Whisper transcribes your speech **offline**
4. Antonio responds with both text and voice
5. Click microphone again to disable voice mode

**No internet required!** All processing happens locally on your device.

---

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  FastAPI Server (Port 8000)                 â”‚
â”‚  â€¢ REST API + WebSocket                     â”‚
â”‚  â€¢ Dual-Model Selector                      â”‚
â”‚  â€¢ Power Sampling (optional)                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚                            â”‚
â”Œâ”€â”€â”€â–¼â”€â”€â”€â”€â”                 â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”
â”‚ SOCIAL â”‚                 â”‚  LOGIC  â”‚
â”‚ Model  â”‚                 â”‚  Model  â”‚
â”‚ (720MB)â”‚                 â”‚ (806MB) â”‚
â””â”€â”€â”€â”¬â”€â”€â”€â”€â”˜                 â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
    â”‚                            â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚      EvoMemoryâ„¢            â”‚
    â”‚   SQLite + RAG-Lite        â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“Š Performance (Raspberry Pi 4)

| Metric | Value |
|--------|-------|
| **Speed** | 3.2-3.6 token/s |
| **Accuracy (Math)** | 92% (LOGIC) vs 78% (SOCIAL) |
| **Accuracy (Code)** | 81% (LOGIC) vs 64% (SOCIAL) |
| **Memory** | ~1.8 GB RAM |
| **Uptime Tested** | 60+ minutes (100% reliability) |

---

## ğŸ³ Docker Deployment

### docker-compose.yml

```yaml
version: '3.8'
services:
  ollama:
    image: ollama/ollama:latest
    ports:
      - "11434:11434"
    volumes:
      - ollama_data:/root/.ollama

  antonio:
    build: .
    ports:
      - "8000:8000"
    depends_on:
      - ollama
    environment:
      - OLLAMA_HOST=ollama:11434
    volumes:
      - ./data:/app/data

volumes:
  ollama_data:
```

---

## ğŸ’¡ Use Cases

**Recommended For:**
- âœ… Home AI assistants (24/7)
- âœ… IoT edge inference
- âœ… Offline chatbots
- âœ… Educational projects
- âœ… Math/coding tutors

**Not Recommended For:**
- âŒ Real-time (<500ms latency)
- âŒ High concurrency (>5 users)
- âŒ Production-scale inference

---

## ğŸ“– Documentation

- **API Docs**: http://localhost:8000/docs (FastAPI Swagger)
- **Models**: [HuggingFace Collection](https://huggingface.co/chill123)
- **Paper** (Power Sampling): [Reasoning with Sampling](https://arxiv.org/abs/...)

---

## ğŸ¤ Contributing

Contributions welcome! Please:
1. Fork the repository
2. Create feature branch (`git checkout -b feature/amazing`)
3. Commit changes (`git commit -m 'Add amazing feature'`)
4. Push to branch (`git push origin feature/amazing`)
5. Open Pull Request

---

## ğŸ“„ License

- **Models**: Gemma License (Google)
- **Code**: MIT License

See [LICENSE](LICENSE) for details.

---

## â˜• Support

If Antonio helped you, consider supporting the project:

**Donate**: https://www.paypal.com/donate/?business=58ML44FNPK66Y&currency_code=EUR

---

**Built with** â¤ï¸ **for offline AI and edge computing**

*"Il piccolo cervello che cresce insieme a te" â€” Antonio AI*
